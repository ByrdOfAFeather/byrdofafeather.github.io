<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-P5SKFSJFL1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-P5SKFSJFL1');
    </script>
    <link type="text/css"
          href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.5/css/bulma.min.css" rel="stylesheet">
    <link type="text/css"
          href="style.css" rel="stylesheet">
    <script src="src.js" type="text/javascript"></script>
    <script
            src="https://code.jquery.com/jquery-3.4.1.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research</title>
</head>
<body>
<div class="container" style="height: 100%">
    <div class="columns is-centered is-vcentered is-multiline" style='margin: 5px 5px 5px 5px'>
        <div class="column is-12">
            <h1 class="title">Research and Engineering</h1>
        </div>
        <div class="column">
            <i class="subtitle">Predicting Difficulty and Discrimination of Natural Language Questions</i>
            <p>Starting in spring of 2020, I began researching a way to generate questions that allowed for specifying how difficult the question should be.</p>


            <p>As a researcher, I <a class="styled_link" href="https://github.com/byrdofafeather/ResearchTestingBed">implemented</a> a seq2seq question generation model, explored various ways of <a class="styled_link" href="https://github.com/ByrdOfAFeather/eduTech/blob/4a26939980e6457628fc2025c4a6b32897974860/irt/irt.ipynb">implementing</a> item response theory,
                and preformed my own <a class="styled_link" href="https://aclanthology.org/2022.acl-short.15/">research</a> on how syntactic and semantic features can predict how difficult a question will be to solve.
                I also explored various practical aspects of Natural Language Processing, including how to fine-tune large language models for down-stream classification tasks. In particular, I have a deep interest in the application of A.I. in education technology which led me to participating in
                a kaggle competition which focused on determining the quality of argumentative essays. This project helped me think about how to setup efficient environments for testing many models in various environments; this mostly stemmed from the
                numerous hyperparameters that come with finte-tuning large language models. My code can be found <a class="styled_link" href="https://github.com/ByrdOfAFeather/pred_essay_quality">here</a>. This project also pushed me to
                familiarized myself with modern mechanisms to interpret predictions from these large language models, including integrated gradients and LIME. I even extended the most popular implementation of LIME and opened a <a href="https://github.com/marcotcr/lime/pull/687" class="styled_link">pull-request</a>, which
                adds the ability to use a T5 model to fill in blanks in data that LIME creates.
                <br>
                <p>I'm currently exploring ways to use natural language feedback to improve models, partly inspiring my <a href="https://github.com/ByrdOfAFeather/fast-weights" class="styled_link">implementation</a>
                of <a href="https://mediatum.ub.tum.de/doc/814768/file.pdf" class="styled_link">fast-weights</a>, in which one model (the slow-network) learns weight updates for another (the fast-network).
                As well, I've taken up studying a classification task in which the goal to is determine the severity of medical errors based on a description of the event, which can be viewed <a href="https://github.com/ByrdOfAFeather/MED" class="styled_link">here</a> when the codebase becomes public.
                </p>
                <br>

            <p>A long time ago, I worked on a cheat detection system for Canvas LMS. This was a desktop app that used an Autoencoder to detect anomalies in testing data. This project was later remade into a website
            and mobile app, but was discontinued to the complexities of a hobby project complying with FERPA. The code base for the website can be found <a class="styled_link" href="https://github.com/ByrdOfAFeather/NARC">here</a> and the desktop app <a class="styled_link" href="https://github.com/ByrdOfAFeather/NARC/tree/legacy">here</a>. </p>
             <br>
                <i>Notice: This page is still under construction</i>
        </div>
    </div>
</body>
</html>